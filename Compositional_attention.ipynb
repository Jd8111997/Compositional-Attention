{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing modules"
      ],
      "metadata": {
        "id": "LN5wEaN63nNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "zet5qMZQ3moy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_zTXyB_qES5",
        "outputId": "d397edf0-e705-4d35-bfe2-23af1f9e193c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-02 04:27:53--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-07-02 04:27:53 (20.0 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm1d:\n",
        "\n",
        "  \"\"\"\n",
        "  Layernorm class.\n",
        "  Inspired from : 'https://github.com/karpathy/ng-video-lecture/blob/master/gpt.py'\n",
        "  Args:\n",
        "    dim = dimension of residual stream.\n",
        "    eps = adding small constant for numerical stability.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dim, eps = 1e-5):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # Calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim = True) # batch mean\n",
        "    xvar = x.var(1, keepdim = True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalization\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n"
      ],
      "metadata": {
        "id": "xkzn7nMSqsO6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Config:\n",
        "\n",
        "  \"\"\"\n",
        "  Hyper-parameters for the model\n",
        "  \"\"\"\n",
        "\n",
        "  batch_size = 16\n",
        "  block_size = 32   # Context length\n",
        "  max_iters = 5000\n",
        "  eval_interval = 100\n",
        "  learning_rate = 1e-3\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  eval_iters = 200\n",
        "  n_embed = 64 # Dimension of token embedding\n",
        "  n_head = 4  # Number od heads\n",
        "  head_size = int(n_embed / n_head) # Input space of each attention head for first attention mechanism\n",
        "  qk_dim = 8  # Dimension vector for secondary attention mechanism\n",
        "  n_rules = 2 # Number of attributes\n",
        "  n_layer = 4 # Number of layers\n",
        "  dropout = 0.0\n",
        "\n",
        "\n",
        "torch.manual_seed(1337)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbMZhsnY0ezG",
        "outputId": "21394750-f75c-426e-a5ed-0fd277b0175d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f86441b5070>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "nuerLh7x6JDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Data preprocessing, Inspired from : 'https://github.com/karpathy/ng-video-lecture/blob/master/gpt.py'\n",
        "'''\n",
        "\n",
        "with open('input.txt', 'r', encoding = 'utf-8') as f:\n",
        "  text = f.read()\n",
        "\n",
        "# Building a vocab of all characters.\n",
        "vocab = sorted(list(set(text)))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Create a tokenizer to map chars to numbers and numbers to chars\n",
        "strtoint = {ch : i for i, ch in enumerate(vocab)}\n",
        "inttostr = {i : ch for i, ch in enumerate(vocab)}\n",
        "\n",
        "# Encoder takes a string and outputs a list of integers.\n",
        "encoder = lambda s : [strtoint[c] for c in s]\n",
        "decoder = lambda l: ''.join([inttostr[i] for i in l])\n",
        "\n",
        "# Preparing training and test splits.\n",
        "data = torch.tensor(encoder(text), dtype = torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# Data loading\n",
        "def get_batch(split):\n",
        "\n",
        "  # generate a small batch of data of inputs x and targets y\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - Config.block_size, (Config.batch_size, ))\n",
        "  x = torch.stack([data[i : i + Config.block_size] for i in ix])\n",
        "  y = torch.stack([data[i + 1 : i + Config.block_size + 1] for i in ix])\n",
        "  x, y = x.to(Config.device), y.to(Config.device)\n",
        "  return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(Config.eval_iters)\n",
        "        for k in range(Config.eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class FCN(nn.Module):\n",
        "\n",
        "  \"\"\"a simple linear layer for attention block\"\"\"\n",
        "\n",
        "  def __init__(self, n_embed, dropout):\n",
        "    super().__init__()\n",
        "    self.fcn_module = nn.Sequential(\n",
        "        nn.Linear(n_embed, 4 * n_embed),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * n_embed, n_embed),\n",
        "        nn.Dropout(dropout),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.fcn_module(x)\n",
        "\n",
        "class Compositional_attention(nn.Module):\n",
        "\n",
        "  def __init__(self, dim, nheads, nrules, qk_dim, head_dim, context_length, dropout):\n",
        "\n",
        "    super(Compositional_attention, self).__init__()\n",
        "    self.dim = dim\n",
        "    self.nheads = nheads\n",
        "    self.nrules = nrules\n",
        "    self.qk_dim = qk_dim\n",
        "    self.head_dim = head_dim\n",
        "    self.context_length = context_length\n",
        "\n",
        "    # Defining Q, K, V for primary attention mechanism.\n",
        "    self.query = nn.Linear(dim, dim)\n",
        "    self.key = nn.Linear(dim, dim)\n",
        "    self.value = nn.Linear(dim, self.head_dim * self.nrules)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(self.context_length, self.context_length)))\n",
        "\n",
        "    # Defining Q, k for secondary attention mechanism.\n",
        "    self.query_value = nn.Linear(dim, self.qk_dim * nheads)\n",
        "    self.key_value = nn.Linear(self.head_dim, self.qk_dim)\n",
        "\n",
        "    # Final projection and dropout layer.\n",
        "    self.projection = nn.Linear(dim, dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    batch_size, context_length, _= x.shape\n",
        "\n",
        "    # Calculating Q, K, V from input as describe in equation 7 in paper.\n",
        "    q = self.query(x).reshape(batch_size, self.nheads, context_length, self.head_dim)\n",
        "    k = self.key(x).reshape(batch_size, self.nheads, self.head_dim, context_length)\n",
        "    v = self.value(x).reshape(batch_size, self.nrules, context_length, self.head_dim).unsqueeze(1)\n",
        "\n",
        "    # Calculating primary causal attention pattern(Search) as describe in equation 8 in paper.\n",
        "    causal_attn_pattrn = torch.matmul(q, k) / (self.head_dim ** 0.5)\n",
        "    causal_attn_pattrn = causal_attn_pattrn.masked_fill(self.tril[:context_length, :context_length] == 0, float('-inf'))\n",
        "    causal_attn_pattrn = F.softmax(causal_attn_pattrn, dim = -1).unsqueeze(2)\n",
        "\n",
        "    # Calculating output(Retrieval = Search * V)\n",
        "    output = torch.matmul(causal_attn_pattrn, v).reshape(batch_size, context_length, self.nheads, self.nrules, self.head_dim)\n",
        "\n",
        "    # Instantiation of Q and K for secondary attention pattern.\n",
        "    q_v = self.query_value(x).reshape(batch_size, context_length, self.nheads, 1, self.qk_dim) / (self.qk_dim ** 0.5)\n",
        "    k_v = self.key_value(output).reshape(batch_size, context_length, self.nheads, self.nrules, self.qk_dim)\n",
        "\n",
        "    # Calculating value score as describe in equation 13 in paper.\n",
        "    comp_score = F.softmax(torch.matmul(q_v, k_v.transpose(4, 3)), dim = -1).reshape(batch_size, context_length, self.nheads, self.nrules, 1)\n",
        "\n",
        "    # Final Compositional score\n",
        "    out = (comp_score * output).sum(dim = 3).reshape(batch_size, context_length, self.dim)\n",
        "    out = self.dropout(self.projection(out))\n",
        "    return out\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, Config):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        self.sa = Compositional_attention(Config.n_embed, Config.n_head, Config.n_rules, Config.qk_dim, Config.head_size, Config.block_size, Config.dropout)\n",
        "        self.ffwd = FCN(Config.n_embed, Config.dropout)\n",
        "        self.ln1 = nn.LayerNorm(Config.n_embed)\n",
        "        self.ln2 = nn.LayerNorm(Config.n_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, Config):\n",
        "        super().__init__()\n",
        "\n",
        "        # Building token and positional embedding martix\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, Config.n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(Config.block_size, Config.n_embed)\n",
        "\n",
        "\n",
        "        self.blocks = nn.Sequential(*[Block(Config) for _ in range(Config.n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(Config.n_embed) # final layer norm\n",
        "        self.lm_head = nn.Linear(Config.n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=Config.device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -Config.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = LanguageModel(Config)\n",
        "m = model.to(Config.device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=Config.learning_rate)\n",
        "\n",
        "for iter in range(Config.max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % Config.eval_interval == 0 or iter == Config.max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=Config.device)\n",
        "print(decoder(m.generate(context, max_new_tokens=2000)[0].tolist()))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMq4M11-58Dd",
        "outputId": "6a88d44b-3ab1-4a4b-9934-d166ab813e3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.211041 M parameters\n",
            "step 0: train loss 4.3630, val loss 4.3649\n",
            "step 100: train loss 2.4564, val loss 2.4700\n",
            "step 200: train loss 1.3903, val loss 1.4081\n",
            "step 300: train loss 0.6807, val loss 0.7069\n",
            "step 400: train loss 0.3956, val loss 0.4124\n",
            "step 500: train loss 0.2821, val loss 0.3015\n",
            "step 600: train loss 0.2412, val loss 0.2493\n",
            "step 700: train loss 0.2094, val loss 0.2128\n",
            "step 800: train loss 0.1924, val loss 0.1985\n",
            "step 900: train loss 0.1823, val loss 0.1886\n",
            "step 1000: train loss 0.1759, val loss 0.1759\n",
            "step 1100: train loss 0.1591, val loss 0.1648\n",
            "step 1200: train loss 0.1413, val loss 0.1428\n",
            "step 1300: train loss 0.1191, val loss 0.1283\n",
            "step 1400: train loss 0.0992, val loss 0.1027\n",
            "step 1500: train loss 0.0929, val loss 0.0976\n",
            "step 1600: train loss 0.0866, val loss 0.0895\n",
            "step 1700: train loss 0.0873, val loss 0.0908\n",
            "step 1800: train loss 0.0838, val loss 0.0851\n",
            "step 1900: train loss 0.0846, val loss 0.0837\n",
            "step 2000: train loss 0.0800, val loss 0.0829\n",
            "step 2100: train loss 0.0796, val loss 0.0798\n",
            "step 2200: train loss 0.0781, val loss 0.0798\n",
            "step 2300: train loss 0.0799, val loss 0.0806\n",
            "step 2400: train loss 0.0785, val loss 0.0809\n",
            "step 2500: train loss 0.0836, val loss 0.0838\n",
            "step 2600: train loss 0.0817, val loss 0.0833\n",
            "step 2700: train loss 0.0765, val loss 0.0780\n",
            "step 2800: train loss 0.0796, val loss 0.0790\n",
            "step 2900: train loss 0.0828, val loss 0.0834\n",
            "step 3000: train loss 0.0770, val loss 0.0790\n",
            "step 3100: train loss 0.0760, val loss 0.0796\n",
            "step 3200: train loss 0.0749, val loss 0.0763\n",
            "step 3300: train loss 0.0746, val loss 0.0751\n",
            "step 3400: train loss 0.0764, val loss 0.0783\n",
            "step 3500: train loss 0.0745, val loss 0.0761\n",
            "step 3600: train loss 0.0772, val loss 0.0787\n",
            "step 3700: train loss 0.0788, val loss 0.0791\n",
            "step 3800: train loss 0.0723, val loss 0.0743\n",
            "step 3900: train loss 0.0750, val loss 0.0780\n",
            "step 4000: train loss 0.0750, val loss 0.0755\n",
            "step 4100: train loss 0.0734, val loss 0.0746\n",
            "step 4200: train loss 0.0721, val loss 0.0724\n",
            "step 4300: train loss 0.0744, val loss 0.0755\n",
            "step 4400: train loss 0.0766, val loss 0.0770\n",
            "step 4500: train loss 0.0751, val loss 0.0763\n",
            "step 4600: train loss 0.0752, val loss 0.0760\n",
            "step 4700: train loss 0.0769, val loss 0.0798\n",
            "step 4800: train loss 0.0739, val loss 0.0774\n",
            "step 4900: train loss 0.0712, val loss 0.0727\n",
            "step 4999: train loss 0.0712, val loss 0.0723\n",
            "\n",
            ",--X,l'!\n",
            "Q'jS 'T:ZZTu; P?WPozKU\n",
            "Hisel bobe to: avegruat the?\n",
            "Thathy:\n",
            "Whit he uwqurthe. bar dilas ate awicr my.\n",
            "\n",
            "ODYA:\n",
            "A Gormure owhy, tofuint you thil; dill, bes if east hain latistlilr,vitt, and the nowirilerans!\n",
            " lalind thall lish, co hivy: thy haiss hiwty. Hull, she Boopetelaves\n",
            "Mom\n",
            "Gll, dimet akllo Windo whry piicale, ath forrive ches imed, poocom thour und kidmy brupt for to igis!\n",
            "Buftongey flerontatfif Pri?\n",
            "\n",
            "KIS? LUCHTINGWERK:\n",
            "God is:\n",
            "Shos brices of thovein couk ay andy vell stoncy thove youn pand, bemary.\n",
            "Your's, gate?\n",
            " so a thy seviren;\n",
            "Thy werten.\n",
            "Wave thot fuld, so no wery ow, with.\n",
            "\n",
            "My somy shint miglom my iass, thal wors.\n",
            "\n",
            "YORK:\n",
            "Thy hemovet: imdint!\n",
            "\n",
            "WAMPTERLYARSit Hoie so ume his VoreRUCRALU:\n",
            "Whit Comy;s\n",
            "Put?\n",
            "What vidh he neesoxlone.\n",
            "\n",
            "KIZHHATher aghercer.\n",
            "Nwy m k shev; buml lem, thor wlll hincrive, morsed\n",
            "Fourd?\n",
            "Ther urd porven in now thity\n",
            "Kive hit ixtiund thorn fit e fut of ip you on what thavirt couglate Blowllke, of so hat thy biver wat hotived:\n",
            "Hher, forc;\n",
            "your whice worrond, bruwe hafl it fut Hink;\n",
            "Couth Rutcong hod cor thit to tono:\n",
            "Way ho shir!\n",
            "\n",
            "AM:\n",
            "Firsevimines so teall hingin in thy highliWHAn wowh, watla blars and: hy pevInirst a catint to may, the an bigketimy lamenato linten thing brwimavise. hawe e woll, in;to so tho your Hhacher motlalllalow!\n",
            "And foll conot jora difr of thrif ther arling mas, hin thil clid hinl tor Whou holl my tham thy by:\n",
            "Hher of vonby the to thom ther ber whor;\n",
            "Wale it your to maver fore you thel!\n",
            "Hifins yiey:\n",
            "Ans arrallllers ther, shon of my houk happowrars, evas;\n",
            "Roll, tholk!---tste my futters\n",
            "AALORCH:\n",
            "My, Boringis in\n",
            "My ve wacld.\n",
            "\n",
            "IUCHHORCHLOK VINTERTh prrill's!\n",
            "Whes tham wold. ar?\n",
            "And arit, give ath, coufm hir, byoass of th, mathes.\n",
            "Bry Helly no en: hit wifl ler for that hy cry, thof that amt, licholl?\n",
            "And-y uat thit with faintall'd of!\n",
            "A bur the ther, to lifl he poot food.\n",
            "\n",
            "YORVIUCET:\n",
            "Wher:\n",
            "And fanes yoot youm, bave nowave,sent, Joan dath you fato, Jir of patfing:\n",
            "In fo shy nove.\n",
            "What me so mer to hihe wowho \n",
            "Mare\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Td8kEssNwSXQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}